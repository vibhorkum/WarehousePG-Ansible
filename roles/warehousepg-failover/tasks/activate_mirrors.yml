---
# Activate segment mirrors as new primaries

- name: Get DR coordinator details for segment operations
  set_fact:
    dr_coordinator_host: "{{ groups['whpg_dr_coordinator'][0] }}"
  run_once: true

- name: Get DR segment hosts
  set_fact:
    dr_segment_hosts: "{{ groups['whpg_dr_segments'] | default([]) }}"
  run_once: true

# CRITICAL: After DR takeover, the mirror segments need to be promoted
# Remove standby.signal file to allow them to start as primaries
- name: Remove standby.signal from DR segment mirrors
  become: yes
  become_user: gpadmin
  shell: |
    echo "=== Removing standby.signal files to allow segments to start as primaries ==="
    for dir in /data/mirror/seg*/; do
      if [ -f "${dir}standby.signal" ]; then
        echo "Removing ${dir}standby.signal"
        rm -f "${dir}standby.signal"
      else
        echo "No standby.signal in ${dir}"
      fi
    done
    echo "Done removing standby.signal files"
  delegate_to: "{{ item }}"
  loop: "{{ dr_segment_hosts }}"
  register: remove_standby_signal
  when:
    - whpg_failover_dr_takeover | default(true)
    - dr_segment_hosts | length > 0
  ignore_errors: yes

- name: Display standby.signal removal result
  debug:
    msg: "{{ item.stdout_lines if item.stdout_lines is defined else 'Skipped' }}"
  loop: "{{ remove_standby_signal.results | default([]) }}"
  when:
    - remove_standby_signal is defined
    - remove_standby_signal.results is defined

# Clean up any stale shared memory on DR segments
- name: Clean up stale shared memory on DR segments
  become: yes
  become_user: gpadmin
  shell: |
    echo "=== Cleaning up stale shared memory ==="
    # Remove postmaster.pid files if postgres is not running
    for dir in /data/mirror/seg*/; do
      if [ -f "${dir}postmaster.pid" ]; then
        # Check if the PID is actually running
        PID=$(head -1 "${dir}postmaster.pid" 2>/dev/null || echo "")
        if [ -n "$PID" ] && ! kill -0 "$PID" 2>/dev/null; then
          echo "Removing stale postmaster.pid in ${dir}"
          rm -f "${dir}postmaster.pid"
        fi
      fi
    done
    # Clear any stale shared memory segments
    for shmid in $(ipcs -m 2>/dev/null | awk '/gpadmin/ {print $2}'); do
      ipcrm -m "$shmid" 2>/dev/null || true
    done
    echo "Shared memory cleanup complete"
  delegate_to: "{{ item }}"
  loop: "{{ dr_segment_hosts }}"
  when:
    - whpg_failover_dr_takeover | default(true)
    - dr_segment_hosts | length > 0
  ignore_errors: yes

- name: Check segment status on new primary
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    gpstate -e
  delegate_to: "{{ dr_coordinator_host }}"
  register: segment_status
  changed_when: false
  failed_when: false
  run_once: true

- name: Display current segment status
  debug:
    var: segment_status.stdout_lines
  run_once: true

- name: Check for down segments
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -t -c "
      SELECT count(*) 
      FROM gp_segment_configuration 
      WHERE status = 'd';
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: down_segments
  changed_when: false
  run_once: true

- name: Display down segment count
  debug:
    msg: "Down segments: {{ down_segments.stdout | trim }}"
  run_once: true

- name: Check segment configuration after promotion
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -c "
      SELECT content, role, preferred_role, status, hostname, port, datadir
      FROM gp_segment_configuration
      ORDER BY content, role;
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: segment_config
  changed_when: false
  run_once: true

- name: Display segment configuration
  debug:
    var: segment_config.stdout_lines
  run_once: true

# After failover, old primaries are down, mirrors (now on DR) should be up
# If mirrors are still showing as mirrors but up, they've taken over as acting primaries
- name: Check if segment recovery is needed
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -t -c "
      SELECT count(*) 
      FROM gp_segment_configuration 
      WHERE status = 'd' AND role = 'p';
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: down_primaries
  changed_when: false
  run_once: true

- name: Check if mirrors need to be promoted (role != preferred_role)
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -t -c "
      SELECT count(*) 
      FROM gp_segment_configuration 
      WHERE role != preferred_role AND content >= 0;
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: unbalanced_segments
  changed_when: false
  run_once: true

- name: Display recovery assessment
  debug:
    msg:
      - "Down primary segments: {{ down_primaries.stdout | trim }}"
      - "Unbalanced segments (role != preferred_role): {{ unbalanced_segments.stdout | trim }}"
      - "DR takeover mode: {{ whpg_failover_dr_takeover | default(true) }}"
  run_once: true

# When DR takeover is enabled and old primaries are down, mirrors have already become acting primaries
# We need to update the catalog to reflect this and set new preferred roles
- name: Recover segments - mirrors become new primaries
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    echo "=== Current segment status ==="
    gpstate -e
    echo ""
    echo "=== Running gprecoverseg -a to recover from failed primaries ==="
    gprecoverseg -a || true
  delegate_to: "{{ dr_coordinator_host }}"
  register: recover_segments
  when: down_primaries.stdout | trim | int > 0
  run_once: true
  ignore_errors: yes

- name: Display recovery result
  debug:
    msg: "{{ recover_segments.stdout_lines if recover_segments is defined and recover_segments.changed else 'No segment recovery needed' }}"
  run_once: true

- name: Wait for segment recovery to complete
  pause:
    seconds: 30
  when: recover_segments is defined and recover_segments.changed
  run_once: true

# After DR takeover, we need to:
# 1. Wait for mirrors-turned-primaries to be fully operational
# 2. Update preferred roles so DR segments are now the preferred primaries
# 3. Optionally recover the old primary site as new mirrors
- name: Update segment preferred roles for DR takeover
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    echo "=== Checking segment configuration after failover ==="
    psql -d template1 -c "SELECT content, role, preferred_role, status, mode, hostname FROM gp_segment_configuration WHERE content >= 0 ORDER BY content, role;"
    
    # Check if segments have failed over (DR segments are now acting as primaries)
    ACTING_PRIMARIES=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE role = 'p' AND hostname LIKE '%site2%' OR hostname LIKE '%dr-%' OR hostname LIKE '%segment-repl%';" | tr -d ' ')
    echo ""
    echo "DR segments acting as primaries: $ACTING_PRIMARIES"
    
    # Check if role != preferred_role (failover happened)
    UNBALANCED=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE role != preferred_role AND content >= 0;" | tr -d ' ')
    echo "Segments with role != preferred_role: $UNBALANCED"
    
    if [ "$UNBALANCED" -gt 0 ]; then
      echo ""
      echo "=== Segments have failed over - mirrors are now acting as primaries ==="
      echo "These segments need rebalancing or preferred role update"
      psql -d template1 -c "SELECT content, role, preferred_role, hostname FROM gp_segment_configuration WHERE role != preferred_role AND content >= 0;"
    fi
  delegate_to: "{{ dr_coordinator_host }}"
  register: check_failover_status
  run_once: true
  changed_when: false

- name: Display failover status
  debug:
    msg: "{{ check_failover_status.stdout_lines }}"
  run_once: true

- name: Rebalance segments if needed (swap roles back to preferred)
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    # Check if rebalance is needed
    UNBALANCED=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE role != preferred_role AND content >= 0;" | tr -d ' ')
    
    if [ "$UNBALANCED" -gt 0 ]; then
      # Check if old primaries (site1) are accessible for rebalance
      DOWN_COUNT=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE status = 'd' AND content >= 0;" | tr -d ' ')
      
      if [ "$DOWN_COUNT" -gt 0 ]; then
        echo "Old primary segments are still down ($DOWN_COUNT segments)"
        echo "Skipping rebalance - DR segments will remain as primaries"
        echo "To recover old primaries as mirrors, run: gprecoverseg -aF"
        echo ""
        echo "Current configuration (DR segments are acting primaries):"
        psql -d template1 -c "SELECT content, role, preferred_role, status, hostname FROM gp_segment_configuration WHERE content >= 0 ORDER BY content, role;"
      else
        echo "All segments are up - rebalancing to preferred roles..."
        gprecoverseg -ra
      fi
    else
      echo "No rebalancing needed - all segments match preferred roles"
    fi
  delegate_to: "{{ dr_coordinator_host }}"
  register: rebalance_segments
  run_once: true
  ignore_errors: yes

- name: Display rebalance result
  debug:
    msg: "{{ rebalance_segments.stdout_lines }}"
  run_once: true
  when: rebalance_segments is defined

- name: Wait for FTS to update segment status
  pause:
    seconds: 15
  run_once: true

- name: Trigger FTS probe to refresh segment status
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    gpstate -e
  delegate_to: "{{ dr_coordinator_host }}"
  register: fts_probe
  changed_when: false
  run_once: true

- name: Display updated segment status
  debug:
    var: fts_probe.stdout_lines
  run_once: true
