---
# Activate segment mirrors as new primaries

- name: Get DR coordinator details for segment operations
  set_fact:
    dr_coordinator_host: "{{ groups['whpg_dr_coordinator'][0] }}"
  run_once: true

- name: Get DR segment hosts
  set_fact:
    dr_segment_hosts: "{{ groups['whpg_dr_segments'] | default([]) }}"
  run_once: true

# CRITICAL: After DR takeover, the mirror segments need to be promoted
# Remove standby.signal file to allow them to start as primaries
- name: Remove standby.signal from DR segment mirrors
  become: yes
  become_user: gpadmin
  shell: |
    echo "=== Removing standby.signal files to allow segments to start as primaries ==="
    # Use configured directories or fall back to glob pattern
    DIRS="{{ whpg_mirror_data_directories | default([]) | join(' ') }}"
    if [ -z "$DIRS" ]; then
      DIRS=$(ls -d /data/mirror/seg*/ /data/primary/seg*/ /data1/mirror/ /data2/mirror/ 2>/dev/null || true)
    fi
    
    for dir in $DIRS; do
      if [ -d "$dir" ]; then
        for signal in "${dir}/standby.signal" "${dir}standby.signal"; do
          if [ -f "$signal" ]; then
            echo "Removing $signal"
            rm -f "$signal"
          fi
        done
      else
        echo "No directory: $dir"
      fi
    done
    echo "Done removing standby.signal files"
  delegate_to: "{{ item }}"
  loop: "{{ dr_segment_hosts }}"
  register: remove_standby_signal
  when:
    - whpg_failover_dr_takeover | default(true)
    - dr_segment_hosts | length > 0
  ignore_errors: yes

- name: Display standby.signal removal result
  debug:
    msg: "{{ item.stdout_lines if item.stdout_lines is defined else 'Skipped' }}"
  loop: "{{ remove_standby_signal.results | default([]) }}"
  when:
    - remove_standby_signal is defined
    - remove_standby_signal.results is defined

# Clean up any stale shared memory on DR segments
- name: Clean up stale shared memory on DR segments
  become: yes
  become_user: gpadmin
  shell: |
    echo "=== Cleaning up stale shared memory ==="
    # Use configured directories or fall back to glob pattern
    DIRS="{{ whpg_mirror_data_directories | default([]) | join(' ') }}"
    if [ -z "$DIRS" ]; then
      DIRS=$(ls -d /data/mirror/seg*/ /data/primary/seg*/ /data1/mirror/ /data2/mirror/ 2>/dev/null || true)
    fi
    
    # Remove postmaster.pid files if postgres is not running
    for dir in $DIRS; do
      for pidfile in "${dir}/postmaster.pid" "${dir}postmaster.pid"; do
        if [ -f "$pidfile" ]; then
          # Check if the PID is actually running
          PID=$(head -1 "$pidfile" 2>/dev/null || echo "")
          if [ -n "$PID" ] && ! kill -0 "$PID" 2>/dev/null; then
            echo "Removing stale postmaster.pid: $pidfile"
            rm -f "$pidfile"
          fi
        fi
      done
    done
    # Clear any stale shared memory segments
    ipcrm --all=shm 2>/dev/null || for shmid in $(ipcs -m 2>/dev/null | awk '/gpadmin/ {print $2}'); do
      ipcrm -m "$shmid" 2>/dev/null || true
    done
    echo "Shared memory cleanup complete"
  delegate_to: "{{ item }}"
  loop: "{{ dr_segment_hosts }}"
  when:
    - whpg_failover_dr_takeover | default(true)
    - dr_segment_hosts | length > 0
  ignore_errors: yes

- name: Check segment status on new primary
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    gpstate -e
  delegate_to: "{{ dr_coordinator_host }}"
  register: segment_status
  changed_when: false
  failed_when: false
  run_once: true

- name: Display current segment status
  debug:
    var: segment_status.stdout_lines
  run_once: true

- name: Check for down segments
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -t -c "
      SELECT count(*) 
      FROM gp_segment_configuration 
      WHERE status = 'd';
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: down_segments
  changed_when: false
  run_once: true

- name: Display down segment count
  debug:
    msg: "Down segments: {{ down_segments.stdout | trim }}"
  run_once: true

- name: Check segment configuration after promotion
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -c "
      SELECT content, role, preferred_role, status, hostname, port, datadir
      FROM gp_segment_configuration
      ORDER BY content, role;
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: segment_config
  changed_when: false
  run_once: true

- name: Display segment configuration
  debug:
    var: segment_config.stdout_lines
  run_once: true

# After failover, old primaries are down, mirrors (now on DR) should be up
# If mirrors are still showing as mirrors but up, they've taken over as acting primaries
- name: Check if segment recovery is needed
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -t -c "
      SELECT count(*) 
      FROM gp_segment_configuration 
      WHERE status = 'd' AND role = 'p';
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: down_primaries
  changed_when: false
  run_once: true

- name: Check if mirrors need to be promoted (role != preferred_role)
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    psql -d template1 -t -c "
      SELECT count(*) 
      FROM gp_segment_configuration 
      WHERE role != preferred_role AND content >= 0;
    "
  delegate_to: "{{ dr_coordinator_host }}"
  register: unbalanced_segments
  changed_when: false
  run_once: true

- name: Display recovery assessment
  debug:
    msg:
      - "Down primary segments: {{ down_primaries.stdout | trim }}"
      - "Unbalanced segments (role != preferred_role): {{ unbalanced_segments.stdout | trim }}"
      - "DR takeover mode: {{ whpg_failover_dr_takeover | default(true) }}"
  run_once: true

# When DR takeover is enabled and old primaries are down, mirrors have already become acting primaries
# We need to update the catalog to reflect this and set new preferred roles
- name: Recover segments - mirrors become new primaries
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    echo "=== Current segment status ==="
    gpstate -e
    echo ""
    echo "=== Running gprecoverseg -a to recover from failed primaries ==="
    gprecoverseg -a || true
  delegate_to: "{{ dr_coordinator_host }}"
  register: recover_segments
  when: down_primaries.stdout | trim | int > 0
  run_once: true
  ignore_errors: yes

- name: Display recovery result
  debug:
    msg: "{{ recover_segments.stdout_lines if recover_segments is defined and recover_segments.changed else 'No segment recovery needed' }}"
  run_once: true

- name: Wait for segment recovery to complete
  pause:
    seconds: 30
  when: recover_segments is defined and recover_segments.changed
  run_once: true

# After DR takeover, we need to:
# 1. Wait for mirrors-turned-primaries to be fully operational
# 2. Update preferred roles so DR segments are now the preferred primaries
# 3. Optionally recover the old primary site as new mirrors
- name: Update segment preferred roles for DR takeover
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    echo "=== Checking segment configuration after failover ==="
    psql -d template1 -c "SELECT content, role, preferred_role, status, mode, hostname FROM gp_segment_configuration WHERE content >= 0 ORDER BY content, role;"
    
    # Check if segments have failed over (DR segments are now acting as primaries)
    ACTING_PRIMARIES=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE role = 'p' AND hostname LIKE '%site2%' OR hostname LIKE '%dr-%' OR hostname LIKE '%segment-repl%';" | tr -d ' ')
    echo ""
    echo "DR segments acting as primaries: $ACTING_PRIMARIES"
    
    # Check if role != preferred_role (failover happened)
    UNBALANCED=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE role != preferred_role AND content >= 0;" | tr -d ' ')
    echo "Segments with role != preferred_role: $UNBALANCED"
    
    if [ "$UNBALANCED" -gt 0 ]; then
      echo ""
      echo "=== Segments have failed over - mirrors are now acting as primaries ==="
      echo "These segments need rebalancing or preferred role update"
      psql -d template1 -c "SELECT content, role, preferred_role, hostname FROM gp_segment_configuration WHERE role != preferred_role AND content >= 0;"
    fi
  delegate_to: "{{ dr_coordinator_host }}"
  register: check_failover_status
  run_once: true
  changed_when: false

- name: Display failover status
  debug:
    msg: "{{ check_failover_status.stdout_lines }}"
  run_once: true

- name: Rebalance segments if needed (swap roles back to preferred)
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    # Check if rebalance is needed
    UNBALANCED=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE role != preferred_role AND content >= 0;" | tr -d ' ')
    
    if [ "$UNBALANCED" -gt 0 ]; then
      # Check if old primaries (site1) are accessible for rebalance
      DOWN_COUNT=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE status = 'd' AND content >= 0;" | tr -d ' ')
      
      if [ "$DOWN_COUNT" -gt 0 ]; then
        echo "Old primary segments are still down ($DOWN_COUNT segments)"
        echo "Skipping rebalance - DR segments will remain as primaries"
        echo "To recover old primaries as mirrors, run: gprecoverseg -aF"
        echo ""
        echo "Current configuration (DR segments are acting primaries):"
        psql -d template1 -c "SELECT content, role, preferred_role, status, hostname FROM gp_segment_configuration WHERE content >= 0 ORDER BY content, role;"
      else
        echo "All segments are up - rebalancing to preferred roles..."
        gprecoverseg -ra
      fi
    else
      echo "No rebalancing needed - all segments match preferred roles"
    fi
  delegate_to: "{{ dr_coordinator_host }}"
  register: rebalance_segments
  run_once: true
  ignore_errors: yes

- name: Display rebalance result
  debug:
    msg: "{{ rebalance_segments.stdout_lines }}"
  run_once: true
  when: rebalance_segments is defined

- name: Wait for FTS to update segment status
  pause:
    seconds: 15
  run_once: true

- name: Trigger FTS probe to refresh segment status
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    gpstate -e
  delegate_to: "{{ dr_coordinator_host }}"
  register: fts_probe
  changed_when: false
  run_once: true

- name: Display updated segment status
  debug:
    var: fts_probe.stdout_lines
  run_once: true

# ============================================================
# PHASE: Recover old primary segments as new mirrors using gprecoverseg
# This will rebuild the old primary site as mirrors for the new DR-based cluster
# ============================================================
- name: Check if segment recovery is possible
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    echo "=== Checking segment recovery status ==="
    
    # Count down segments
    DOWN_COUNT=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE status = 'd' AND content >= 0;" | tr -d ' ')
    echo "Down segments: $DOWN_COUNT"
    
    # Show which segments are down
    if [ "$DOWN_COUNT" -gt 0 ]; then
      echo ""
      echo "Down segment details:"
      psql -d template1 -c "SELECT content, role, preferred_role, hostname, port, datadir FROM gp_segment_configuration WHERE status = 'd' AND content >= 0 ORDER BY content;"
    fi
    
    echo "$DOWN_COUNT"
  delegate_to: "{{ dr_coordinator_host }}"
  register: recovery_check
  changed_when: false
  run_once: true

- name: Attempt segment recovery with gprecoverseg
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    echo "=== Attempting segment recovery with gprecoverseg ==="
    echo ""
    
    # First try incremental recovery
    echo "Attempting incremental recovery..."
    if gprecoverseg -a 2>&1; then
      echo "Incremental recovery succeeded"
    else
      echo "Incremental recovery failed, this is expected if directories were renamed"
      echo ""
      echo "Attempting full recovery (gprecoverseg -aF)..."
      echo "This will rebuild segments from scratch using the active mirrors"
      
      # Full recovery - rebuilds from scratch
      gprecoverseg -aF 2>&1 || {
        echo ""
        echo "Full recovery also failed."
        echo "This may be because:"
        echo "  1. Old primary hosts are not reachable"
        echo "  2. SSH connectivity issues"
        echo "  3. Disk space issues on old primary hosts"
        echo ""
        echo "Manual recovery steps:"
        echo "  1. Ensure old primary hosts are reachable from DR coordinator"
        echo "  2. Ensure gpadmin can SSH to old primary hosts"
        echo "  3. Run: gprecoverseg -aF manually"
      }
    fi
    
    echo ""
    echo "=== Current segment status after recovery attempt ==="
    gpstate -e
  delegate_to: "{{ dr_coordinator_host }}"
  register: gprecoverseg_result
  when: recovery_check.stdout_lines | last | int > 0
  run_once: true
  ignore_errors: yes

- name: Display gprecoverseg result
  debug:
    msg: "{{ gprecoverseg_result.stdout_lines if gprecoverseg_result is defined and gprecoverseg_result.stdout_lines is defined else 'No segment recovery needed - all segments are up' }}"
  run_once: true

- name: Wait for segment recovery to complete
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    echo "Waiting for segment recovery/resync to complete..."
    for i in $(seq 1 60); do
      # Check if any segments are in resync mode
      RESYNCING=$(psql -d template1 -t -c "SELECT count(*) FROM gp_segment_configuration WHERE mode = 'r' AND content >= 0;" | tr -d ' ')
      
      if [ "$RESYNCING" -eq 0 ]; then
        echo "All segments are synchronized (attempt $i)"
        gpstate -e
        exit 0
      fi
      
      echo "Segments still resyncing: $RESYNCING (attempt $i/60)"
      sleep 10
    done
    
    echo "Warning: Segment resync still in progress after 10 minutes"
    gpstate -e
  delegate_to: "{{ dr_coordinator_host }}"
  register: resync_wait
  when: 
    - gprecoverseg_result is defined
    - gprecoverseg_result.changed | default(false)
  run_once: true
  ignore_errors: yes

- name: Display final cluster status
  become: yes
  become_user: gpadmin
  shell: |
    source {{ whpg_base_dir }}/greenplum_path.sh
    export COORDINATOR_DATA_DIRECTORY={{ whpg_coordinator_data_directory }}
    
    echo "=== Final Cluster Status ==="
    echo ""
    gpstate -s
    echo ""
    echo "=== Segment Configuration ==="
    psql -d template1 -c "SELECT content, role, preferred_role, status, mode, hostname, port FROM gp_segment_configuration ORDER BY content, role;"
  delegate_to: "{{ dr_coordinator_host }}"
  register: final_status
  changed_when: false
  run_once: true

- name: Display final status
  debug:
    var: final_status.stdout_lines
  run_once: true
